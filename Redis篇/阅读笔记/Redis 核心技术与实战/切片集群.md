
# Redis 切片集群

切片集群，也叫分片集群，就是指启动多个 Redis 实例组成一个集群，然后按照一定的规则，把收到的数据划分成多份，每一份用一个实例来保存。

![切片集群架构示意图](.pic/2023-03-18-%E5%88%87%E7%89%87%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84%E7%A4%BA%E6%84%8F%E5%9B%BE.png)

如上图所示，既能保存 25GB 数据，又避免了 fork 子进程阻塞主线程而导致的响应突然变慢。

## 如何保存更多的数据？

**纵向扩展**

升级单个 Redis 实例的资源配置，包括增加内存容量、增加磁盘容量、使用更高配置的 CPU。就像下图中，原来的实例内存是 8GB，硬盘是 50GB，纵向扩展后，内存增加到 24GB，磁盘增加到 150GB。

**横向扩展**

横向增加当前 Redis 实例的个数，就像下图中，原来使用 1 个 8GB 内存、50GB 磁盘的实例，现在使用三个相同配置的实例。

![纵向/横向扩展对比图](.pic/2023-03-18-%E7%BA%B5%E5%90%91%E3%80%81%E6%A8%AA%E5%90%91%E6%89%A9%E5%B1%95%E5%AF%B9%E6%AF%94%E5%9B%BE.png)

**优缺点**

纵向扩展的好处是，实施起来简单、直接。不过，这个方案也面临两个潜在的问题：
+ 当使用 RDB 对数据进行持久化时，如果数据量增加，需要的内存也会增加，主线程 fork 子进程时就可能会阻塞（比如刚刚的例子中的情况）。不过，如果你不要求持久化保存 Redis 数据，那么，纵向扩展会是一个不错的选择。
+ 纵向扩展会受到硬件和成本的限制。这很容易理解，毕竟，把内存从 32GB 扩展到 64GB 还算容易，但是，要想扩充到 1TB，就会面临硬件容量和成本上的限制了。

横向扩展的好处是，不用担心单个实例的硬件和成本限制（百万，千万级别的用户规模，这是个不错的选择）。不过，也存在两个问题：
+ 数据切片后，在多个实例之间如何分布？
+ 客户端怎么确定想要访问的数据在哪个实例上？


### 数据切片和实例的对应分布关系

#### 切片集群和 `Redis Cluster` 的联系与区别
切片集群是一种保存大量数据的通用机制，这个机制可以有不同的实现方案：
1. 在 Redis 3.0 之前，官方并没有针对切片集群提供具体的方案。
2. 从 3.0 开始，官方提供了一个名为 Redis Cluster 的方案，用于实现切片集群。

#### Redis Cluster 方案
Redis Cluster 方案采用哈希槽（Hash Slot），来处理数据和实例之间的映射关系。在Redis Cluster 方案中，一个切片集群共有 16384 个哈希槽（每个键值对都会根据它的key，被映射到一个哈希槽中）。

**映射过程：**
1. 先根据键值对的key，按照CRC16 算法计算一个16 bit 的值；
2. 然后再用这个16 bit 的值对16384 取模，得到0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。

**如何将这些哈希槽映射到具体的 Redis 实例上：**

在部署 Redis Cluster 方案时，可以使用 `cluster create `命令创建集群，此时，Redis 会自动把这些槽平均分布在集群实例上。(例如，如果集群中有 N 个实例，那么，每个实例上的槽个数为 16384/N 个。)

也可以使用 `cluster meet` 命令手动建立实例间的连接，形成集群，再使用 `cluster addslots `命令，指定每个实例上的哈希槽个数。<font color="red">(注意：在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。)</font>

![数据、哈希槽、实例三者映射示意图](.pic/2023-03-18-%E6%95%B0%E6%8D%AE%E3%80%81%E5%93%88%E5%B8%8C%E6%A7%BD%E3%80%81%E5%AE%9E%E4%BE%8B%E4%B8%89%E8%80%85%E6%98%A0%E5%B0%84%E7%A4%BA%E6%84%8F%E5%9B%BE.png)

### 客户端如何定位数据
客户端为什么可以在访问任何一个实例时，都能获得所有的哈希槽信息呢？
> 因为，Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。
>
> 客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。


在集群中，实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个：
1. 在集群中，实例有新增或删除，Redis 需要重新分配哈希槽；
2. 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。

> 此时，实例之间还可以通过相互传递消息，获得最新的哈希槽分配信息，但是，客户端是无法主动感知这些变化的。这就会导致，它缓存的分配信息和最新的分配信息就不一致了

**怎么解决呢？**
Redis Cluster 方案提供了一种**重定向机制**，所谓的“重定向”，就是指，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，客户端要再给一个新实例发送操作命令。

那客户端又是怎么知道重定向时的新实例的访问地址呢？
> 当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，那么，这个实例就会给客户端返回下面的 MOVED 命令响应结果，这个结果中就包含了新实例的访问地址。


```
GET hello:key
(error) MOVED 13320 172.16.19.5:6379
```

MOVED 命令表示：

客户端请求的键值对所在的哈希槽 13320，实际是在 172.16.19.5 这个实例上。通过返回的 MOVED 命令，就相当于把哈希槽所在的新实例的信息告诉给客户端了。这样一来，客户端就可以直接和 172.16.19.5 连接，并发送操作请求了。

![客户端MOVED 重定向命令](.pic/2023-03-18-%E5%AE%A2%E6%88%B7%E7%AB%AFMOVED%20%E9%87%8D%E5%AE%9A%E5%90%91%E5%91%BD%E4%BB%A4.png)

**注意**
> 在上图中，当客户端给实例 2 发送命令时，Slot 2 中的数据已经全部迁移到了实例 3。 在实际应用时，如果 Slot 2 中的数据比较多，就可能会出现一种情况：客户端向实例 2 发送请求，但此时，Slot 2 中的数据只有一部分迁移到了实例 3，还有部分数据没有迁移。在这种迁移部分完成的情况下，客户端就会收到一条 ASK 报错信息，如下所示：

```
GET hello:key (error) ASK 13320 172.16.19.5:6379
```

ASK 命令就表示： 
客户端请求的键值对所在的哈希槽 13320，在 172.16.19.5 这个实例上，但是这个哈希槽正在迁移。此时，客户端需要先给 172.16.19.5 这个实例发送一个 ASKING 命令。这个命令的意思是，让这个实例允许执行客户端接下来发送的命令。然后，客户端再向这个实例发送 GET 命令，以读取数据。

![客户端ASK重定向命令](.pic/2023-03-18-%E5%AE%A2%E6%88%B7%E7%AB%AFASK%E9%87%8D%E5%AE%9A%E5%90%91%E5%91%BD%E4%BB%A4.png)

MOVED 与 ASK 命令的区别：
+ MOVED 命令会更新客户端缓存的哈希槽分配信息；
+ ASK 命令并不会更新客户端缓存的哈希槽分配信息。


所以，在上图中，如果客户端再次请求 Slot 2 中的数据，它还是会给实例 2 发送请求。这也就是说，ASK 命令的作用只是让客户端能给新实例发送一次请求，而不像 MOVED 命令那样，会更改本地缓存，让后续所有命令都发往新实例。