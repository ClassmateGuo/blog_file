## 为什么会发生脑裂？

最开始，作者大大在主从集群中，客户端发送的数据丢失了，然后开始了问题的查询过程

## 第一步：确认是不是数据同步出现了问题

在主从集群中发生数据丢失，最常见的原因就是主库的数据还没有同步到从库，结果主库发生了故障，等从库升级为主库后，未同步的数据就丢失了。

![数据未同步丢失示意图](.pic/2023-03-27-%E6%95%B0%E6%8D%AE%E6%9C%AA%E5%90%8C%E6%AD%A5%E4%B8%A2%E5%A4%B1%E7%A4%BA%E6%84%8F%E5%9B%BE.png)

> 如果是这种情况的数据丢失，可以通过比对主从库上的复制进度差值来进行判断，也就是计算 `master_repl_offset` 和 `slave_repl_offset` 的差值。如果从库上的 `slave_repl_offset` 小于原主库的 `master_repl_offset`，那么，就可以认定数据丢失是由数据同步未完成导致的。

## 第二步：排查客户端的操作日志，发现脑裂现象

在排查客户端的操作日志时，发现，在主从切换后的一段时间内，有一个客户端仍然在和原主库通信，并没有和升级的新主库进行交互。这就相当于主从集群中同时有了两个主库。根据这个迹象，就想到了在分布式主从集群发生故障时会出现的一个问题：脑裂。

> 但是，不同客户端给两个主库发送数据写操作，按道理来说，只会导致新数据会分布在不同的主库上，并不会造成数据丢失。那么，为什么数据仍然丢失了呢？

## 第三步：发现是原主库假故障导致的脑裂

采用哨兵机制进行主从切换的，当主从切换发生时，一定是有超过预设数量（`quorum` 配置项）的哨兵实例和主库的心跳都超时了，才会把主库判断为客观下线，然后，哨兵开始执行切换操作。哨兵切换完成后，客户端会和新主库进行通信，发送请求操作。

> 但是，在切换过程中，既然客户端仍然和原主库通信，这就表明，***原主库并没有真的发生故障（例如主库进程挂掉）***。猜测，主库是由于某些原因无法处理请求，也没有响应哨兵的心跳，才被哨兵错误地判断为客观下线的。结果，在被判断下线之后，原主库又重新开始处理请求了，而此时，哨兵还没有完成主从切换，客户端仍然可以和原主库通信，客户端发送的写操作就会在原主库上写入数据了。


**作者大大的测试：**

    为了验证原主库只是“假故障”，我们也查看了原主库所在服务器的资源使用监控记录。

    的确，我们看到原主库所在的机器有一段时间的 CPU 利用率突然特别高，这是我们在机器上部署的一个数据采集程序导致的。因为这个程序基本把机器的 CPU 都用满了，导致 Redis 主库无法响应心跳了，在这个期间内，哨兵就把主库判断为客观下线，开始主从切换了。不过，这个数据采集程序很快恢复正常，CPU 的使用率也降下来了。此时，原主库又开始正常服务请求了。

    正因为原主库并没有真的发生故障，我们在客户端操作日志中就看到了和原主库的通信记录。等到从库被升级为新主库后，主从集群里就有两个主库了，到这里，我们就把脑裂发生的原因摸清楚了。

![脑裂的发生过程](.pic/2023-03-27-%E8%84%91%E8%A3%82%E7%9A%84%E5%8F%91%E7%94%9F%E8%BF%87%E7%A8%8B.png)


## 为什么脑裂会导致数据丢失？

> 主从切换后，从库一旦升级为新主库，哨兵就会让原主库执行 `slave of` 命令，和新主库重新进行全量同步。***而在全量同步执行的最后阶段，原主库需要清空本地的数据，加载新主库发送的 `RDB` 文件*** ，这样一来，原主库在主从切换期间保存的新写数据就丢失了。

![原主库数据丢失过程](.pic/2023-03-27-%E5%8E%9F%E4%B8%BB%E5%BA%93%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E8%BF%87%E7%A8%8B.png)


## 问题的发生过程和原因小总结
在主从切换的过程中，如果原主库只是“假故障”，它会触发哨兵启动主从切换，一旦等它从假故障中恢复后，又开始处理请求，这样一来，就会和新主库同时存在，形成脑裂。等到哨兵让原主库和新主库做全量同步后，原主库在切换期间保存的数据就丢失了。

## 如何应对脑裂问题？

主从集群中的数据丢失事件，归根结底是因为发生了脑裂。发现问题是出在原主库发生假故障后仍然能接收请求上，那就开始在主从集群机制的配置项中查找是否有限制主库接收请求的设置。

通过查找发现，Redis 已经提供了两个配置项来限制主库的请求处理，分别是 `min-slaves-to-write` 和 `min-slaves-max-lag`，有了这两个配置项后，就可以轻松地应对脑裂问题了：

+ `min-slaves-to-write`：这个配置项设置了主库能进行数据同步的最少从库数量；
+ `min-slaves-max-lag`：这个配置项设置了主从库间进行数据复制时，从库给主库发送 ACK 消息的最大延迟（以秒为单位）。

可以把 `min-slaves-to-write` 和 `min-slaves-max-lag` 这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设为 `N` 和 `T`。这两个配置项组合后的要求是：***主库连接的从库中至少有 `N` 个从库，和主库进行数据复制时的 `ACK` 消息延迟不能超过 `T` 秒，否则，主库就不会再接收客户端的请求了***。

> 即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行 `ACK` 确认了。这样一来，`min-slaves-to-write` 和 `min-slaves-max-lag` 的组合要求就无法得到满足，原主库就会被限制接收客户端请求，客户端也就不能在原主库中写入新数据了。
> 
> 等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。

### 举个例子。

假设将 `min-slaves-to-write` 设置为 `1`，把 `min-slaves-max-lag `设置为 `12s`，把哨兵的 `down-after-milliseconds` 设置为 `10s`，主库因为某些原因卡住了 `15s`，导致哨兵判断主库客观下线，开始进行主从切换。同时，因为原主库卡住了 `15s`，没有一个从库能和原主库在 `12s` 内进行数据复制，原主库也无法接收客户端请求了。这样一来，主从切换完成后，也只有新主库能接收请求，不会发生脑裂，也就不会发生数据丢失的问题了。